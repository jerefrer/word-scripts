#!/usr/bin/env python3
"""Insert phonetics into DOCX files using the Lingua-BO-Wylie perl toolkit."""

from __future__ import annotations

import argparse
import os
import shutil
import subprocess
import sys
import tempfile
from pathlib import Path
from typing import Iterable, List, Sequence, Tuple

try:
    from docx import Document
    from docx.enum.style import WD_STYLE_TYPE
    from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_LINE_SPACING
    from docx.oxml import OxmlElement
    from docx.shared import Mm, Pt
    from docx.text.paragraph import Paragraph
except ImportError as error:  # pragma: no cover - runtime guard
    sys.stderr.write(
        "python-docx is required. Install it with `pip install python-docx` before running this script.\n"
    )
    raise

SCRIPT_DIR = Path(__file__).resolve().parent
LINGUA_DIR = SCRIPT_DIR / "Lingua-BO-Wylie"
PERL_LIB_PATH = LINGUA_DIR / "lib"
PERL_SCRIPT_PATH = LINGUA_DIR / "bin" / "pronounce.pl"
DEFAULT_TIBETAN_STYLE = "Verse Tibetan"
DEFAULT_PHONETICS_STYLE = "Verse Phonetics"
DEFAULT_INSERTED_TIBETAN_STYLE = "Inserted Verse Tibetan"
DEFAULT_INSERTED_PHONETICS_STYLE = "Inserted Verse Phonetics"
DEFAULT_MANTRA_STYLE = "Mantra Tibetan"
DEFAULT_SKIP_CHAR_STYLE = "Yigchung Tibetan Characters"
DEFAULT_MANTRA_CHAR_STYLE = "Sanskrit at the beginning"
GYUR_SUFFIX = " gyur"
GYUR_TRIGGER_PHRASES = {
    "མོས་ལ",
    "བལྟས་ལ",
    "བསམ",
    "བསམ་ལ",
    "བསམ་མོ",
    "བསམ་ཞིང",
    "བསམ་ཞིང་",
    "བསམ་ལ་བཟླ་ཞིང",
    "བསམ་ལ་བཟླ་ཞིང་",
    "གསལ་གདབ",
    "མོས་པའི་ང་རྒྱལ་བསྐྱེད་དེ",
}
MANTRA_PREFIXES = {
    "ཨོཾ་ཨཱཿཧཱུྃ",
    "ཧཱུྃ་ཧཱུྃ་ཧཱུྃ",
    "ཧཱུྃ",
    "ན་མོ",
    "ཨོཾ",
    "བྷྲཱུ",
    "རཾ་ཡཾ་ཁཾ",
    "ཛཿཧཱུྃ་བཾ་ཧོཿ",
}
MAX_MANTRA_SYLLABLES = 3
TIBETAN_ENDING_PUNCTUATION = "།༎༑༏༐༔"
TIBSKRIT_SCRIPT = SCRIPT_DIR / "tibskrit-transliterator-cli.js"
_TIBSKRIT_WARNING_EMITTED = False


def collect_docx_files(paths: Iterable[str]) -> List[Path]:
    docx_files: List[Path] = []
    for raw_path in paths:
        path = Path(raw_path).expanduser().resolve()
        if path.is_file():
            if _is_valid_docx(path):
                docx_files.append(path)
            else:
                sys.stderr.write(f"Skipped {path}: not a valid .docx file.\n")
        elif path.is_dir():
            for file_path in sorted(path.rglob("*.docx")):
                if _is_valid_docx(file_path):
                    docx_files.append(file_path.resolve())
        else:
            sys.stderr.write(f"Skipped {path}: not a .docx file or directory.\n")
    return docx_files


def _is_valid_docx(path: Path) -> bool:
    return path.suffix.lower() == ".docx" and not path.name.startswith("~$")


def ensure_perl_prerequisites() -> None:
    if shutil.which("perl") is None:
        raise RuntimeError("Perl is not available on PATH. Install it (e.g. `brew install perl`).")
    if not PERL_SCRIPT_PATH.exists():
        raise FileNotFoundError(f"Perl script not found at {PERL_SCRIPT_PATH}")
    if not PERL_LIB_PATH.exists():
        raise FileNotFoundError(f"Perl lib directory not found at {PERL_LIB_PATH}")


def generate_phonetics_for_group(text: str) -> str:
    if not text.strip():
        return ""
    with tempfile.TemporaryDirectory() as tmp_dir:
        tmp_dir_path = Path(tmp_dir)
        input_path = tmp_dir_path / "phonetics_input.txt"
        output_path = tmp_dir_path / "phonetics_output.txt"
        input_path.write_text(text, encoding="utf-8")
        command = [
            "perl",
            f"-I{PERL_LIB_PATH}",
            str(PERL_SCRIPT_PATH),
            "-sty",
            "padmakara-pt",
            str(input_path),
            str(output_path),
        ]
        subprocess.run(command, check=True, capture_output=True)
        if not output_path.exists():
            raise RuntimeError("Phonetics output file was not generated.")
        result = output_path.read_text(encoding="utf-8")
    sanitized = _clean_phonetics_text(result)
    if not sanitized:
        return ""
    return sanitized[0].upper() + sanitized[1:]


def _clean_phonetics_text(text: str) -> str:
    stripped = text.replace("\r", "").replace("\n", "").strip()
    return "".join(
        ch for ch in stripped if (ord(ch) >= 0x20) or ch == "\t"
    )


def generate_phonetics_line(text: str) -> str:
    groups = [group for group in text.split() if group.strip()]
    phonetics_segments: List[str] = []
    for group in groups:
        phonetics = generate_phonetics_for_group(group)
        if phonetics:
            phonetics_segments.append(phonetics)
    return "   ".join(phonetics_segments)


def insert_phonetics_paragraph(
    paragraph: Paragraph,
    segments: Sequence[Tuple[str, str | None]],
    style_name: str,
) -> Paragraph:
    new_p = OxmlElement("w:p")
    paragraph._p.addnext(new_p)
    new_paragraph = Paragraph(new_p, paragraph._parent)
    new_paragraph.style = style_name
    for text, char_style in segments:
        if not text:
            continue
        run = new_paragraph.add_run(text)
        if char_style:
            run.style = char_style
    return new_paragraph


def ensure_phonetics_style(document: Document, style_name: str) -> None:
    try:
        document.styles[style_name]
        return
    except KeyError:
        pass

    style = document.styles.add_style(style_name, WD_STYLE_TYPE.PARAGRAPH)
    paragraph_format = style.paragraph_format
    paragraph_format.line_spacing_rule = WD_LINE_SPACING.EXACTLY
    paragraph_format.line_spacing = Pt(36)
    paragraph_format.space_before = Mm(1)
    paragraph_format.alignment = WD_ALIGN_PARAGRAPH.LEFT

    font = style.font
    font.name = "Arial"
    font.size = Pt(14)
    font.bold = False
    font.italic = False


def process_docx(
    path: Path,
    style_pairs: Sequence[tuple[str, str]],
    mantra_style: str | None,
    skip_char_style: str | None,
    mantra_char_style: str | None,
) -> int:
    document = Document(path)
    seen_phonetics_styles = {
        phonetics_style for _, phonetics_style in style_pairs if phonetics_style
    }
    for style_name in seen_phonetics_styles:
        ensure_phonetics_style(document, style_name)
    _ensure_mantra_char_style(document, mantra_char_style)
    inserted_count = 0
    index = 0
    tibetan_to_phonetics = {t: p for t, p in style_pairs if t and p}
    while True:
        paragraphs = document.paragraphs
        if index >= len(paragraphs):
            break
        paragraph = paragraphs[index]
        paragraph_style = paragraph.style.name if paragraph.style is not None else ""
        phonetics_style = tibetan_to_phonetics.get(paragraph_style)
        if phonetics_style:
            next_paragraph = paragraphs[index + 1] if index + 1 < len(paragraphs) else None
            next_style = next_paragraph.style.name if next_paragraph and next_paragraph.style else ""
            if mantra_style and next_style == mantra_style:
                index += 1
                continue
            if next_style == phonetics_style and next_paragraph and next_paragraph.text.strip():
                index += 2
                continue
            segments = _build_phonetics_segments(
                paragraph,
                skip_char_style,
                mantra_char_style,
            )
            if segments:
                insert_phonetics_paragraph(paragraph, segments, phonetics_style)
                inserted_count += 1
                index += 2
                continue
        index += 1
    if inserted_count:
        _safe_save_document(document, path)
    return inserted_count


def _safe_save_document(document: Document, destination: Path) -> None:
    destination = Path(destination)
    destination.parent.mkdir(parents=True, exist_ok=True)
    with tempfile.NamedTemporaryFile(
        prefix=f"{destination.stem}_",
        suffix=destination.suffix,
        dir=str(destination.parent),
        delete=False,
    ) as tmp_file:
        temp_path = Path(tmp_file.name)
    try:
        document.save(temp_path)
        temp_path.replace(destination)
    finally:
        if temp_path.exists():
            temp_path.unlink()


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Insert phonetics paragraphs into .docx files.")
    parser.add_argument("paths", nargs="+", help="Files or folders to scan for .docx documents")
    parser.add_argument("--tibetan-style", default=DEFAULT_TIBETAN_STYLE, dest="tibetan_style")
    parser.add_argument("--phonetics-style", default=DEFAULT_PHONETICS_STYLE, dest="phonetics_style")
    parser.add_argument(
        "--inserted-tibetan-style",
        default=DEFAULT_INSERTED_TIBETAN_STYLE,
        dest="inserted_tibetan_style",
        help=(
            "Additional Tibetan style to process (default: %(default)s). "
            "Pass an empty string to disable."
        ),
    )
    parser.add_argument(
        "--inserted-phonetics-style",
        default=DEFAULT_INSERTED_PHONETICS_STYLE,
        dest="inserted_phonetics_style",
        help=(
            "Phonetics style to use for the inserted Tibetan style (default: %(default)s). "
            "Ignored if --inserted-tibetan-style is empty."
        ),
    )
    parser.add_argument("--mantra-style", default=DEFAULT_MANTRA_STYLE, dest="mantra_style")
    parser.add_argument(
        "--skip-char-style",
        default=DEFAULT_SKIP_CHAR_STYLE,
        dest="skip_char_style",
        help=(
            "Character style whose text should be excluded from phonetics generation. "
            "Pass an empty string to disable."
        ),
    )
    parser.add_argument(
        "--mantra-char-style",
        default=DEFAULT_MANTRA_CHAR_STYLE,
        dest="mantra_char_style",
        help=(
            "Character style applied to transliterated mantra prefixes (default: %(default)s). "
            "Pass an empty string to disable styling."
        ),
    )
    parser.add_argument(
        "--no-mantra",
        action="store_true",
        help="Disable mantra style check (phonetics will also be inserted before mantra paragraphs).",
    )
    return parser.parse_args()


def main() -> None:
    args = parse_args()
    mantra_style = None if args.no_mantra else args.mantra_style
    skip_char_style = args.skip_char_style.strip() or None
    mantra_char_style = args.mantra_char_style.strip() or None
    style_pairs: List[tuple[str, str]] = [(args.tibetan_style, args.phonetics_style)]
    inserted_tibetan_style = args.inserted_tibetan_style.strip()
    inserted_phonetics_style = args.inserted_phonetics_style.strip()
    if inserted_tibetan_style and inserted_phonetics_style:
        style_pairs.append((inserted_tibetan_style, inserted_phonetics_style))
    ensure_perl_prerequisites()
    docx_files = collect_docx_files(args.paths)
    if not docx_files:
        sys.stderr.write("No .docx files found.\n")
        return
    total_inserted = 0
    for docx_path in docx_files:
        try:
            inserted = process_docx(
                docx_path,
                style_pairs,
                mantra_style,
                skip_char_style,
                mantra_char_style,
            )
            total_inserted += inserted
            print(f"{docx_path}: inserted {inserted} phonetics paragraph(s)")
        except subprocess.CalledProcessError as error:
            sys.stderr.write(f"Failed to generate phonetics for {docx_path}: {error}\n")
        except Exception as error:  # pragma: no cover - defensive
            sys.stderr.write(f"Error processing {docx_path}: {error}\n")
    print(f"Done. Total phonetics paragraphs inserted: {total_inserted}")


def _paragraph_text_for_phonetics(paragraph: Paragraph, skip_char_style: str | None) -> str:
    if not skip_char_style:
        return paragraph.text
    fragments: List[str] = []
    for run in paragraph.runs:
        text = run.text
        if not text:
            continue
        style_name = _style_name(getattr(run, "style", None))
        if style_name == skip_char_style:
            fragments.append(" ")
        else:
            fragments.append(text)
    return "".join(fragments)


def _style_name(style) -> str | None:
    if style is None:
        return None
    return getattr(style, "name", None) or str(style)


def _build_phonetics_segments(
    paragraph: Paragraph,
    skip_char_style: str | None,
    mantra_char_style: str | None,
) -> List[Tuple[str, str | None]]:
    source_text = _paragraph_text_for_phonetics(paragraph, skip_char_style)
    if not source_text.strip():
        return []
    mantra_prefix, remainder = _split_mantra_prefix(source_text)
    segments: List[Tuple[str, str | None]] = []
    if mantra_prefix:
        mantra_phonetics = _transliterate_mantra_with_tibskrit(mantra_prefix)
        if mantra_phonetics:
            char_style = mantra_char_style if mantra_char_style else None
            segments.append((mantra_phonetics.strip(), char_style))
    rest_source = remainder if mantra_prefix else source_text
    rest_phonetics = generate_phonetics_line(rest_source) if rest_source.strip() else ""
    if mantra_prefix and rest_phonetics.strip():
        segments.append(("   ", None))
    if rest_phonetics.strip():
        segments.append((rest_phonetics.strip(), None))
    if segments and _needs_gyur_suffix(paragraph, skip_char_style):
        _append_suffix_to_segments(segments, GYUR_SUFFIX)
    return segments


def _split_mantra_prefix(text: str) -> Tuple[str | None, str]:
    stripped = text.strip()
    if not stripped:
        return None, ""
    parts = stripped.split(None, 2)
    if len(parts) < 2:
        return None, stripped
    prefix_raw = parts[0]
    rest = stripped[len(prefix_raw):].lstrip()
    prefix = _strip_tibetan_punctuation(prefix_raw)
    if prefix and _is_short_mantra(prefix):
        return prefix, rest
    return None, stripped


def _transliterate_mantra_with_tibskrit(text: str) -> str:
    if not text.strip():
        return ""
    fallback = generate_phonetics_line(text).strip()
    with tempfile.NamedTemporaryFile("w", encoding="utf-8", delete=False) as tmp_file:
        tmp_file.write(text)
        tmp_path = Path(tmp_file.name)
    command = ["node", str(TIBSKRIT_SCRIPT), str(tmp_path), "false"]
    try:
        result = subprocess.run(
            command,
            check=True,
            capture_output=True,
            text=True,
        )
        return result.stdout.strip() or fallback
    except (subprocess.CalledProcessError, FileNotFoundError, PermissionError) as error:
        _emit_tibskrit_warning(error)
        return fallback
    finally:
        if tmp_path.exists():
            tmp_path.unlink()


def _emit_tibskrit_warning(error: Exception) -> None:
    global _TIBSKRIT_WARNING_EMITTED
    if _TIBSKRIT_WARNING_EMITTED:
        return
    _TIBSKRIT_WARNING_EMITTED = True
    sys.stderr.write(
        "Warning: tibskrit transliteration failed (" f"{error}" "). Falling back to default phonetics.\n"
    )


def _is_short_mantra(text: str) -> bool:
    if text in MANTRA_PREFIXES:
        return True
    syllables = [part for part in text.split("་") if part.strip(TIBETAN_ENDING_PUNCTUATION + " ")]
    return 0 < len(syllables) <= MAX_MANTRA_SYLLABLES


def _append_suffix_to_segments(segments: List[Tuple[str, str | None]], suffix: str) -> None:
    for index in range(len(segments) - 1, -1, -1):
        text, style = segments[index]
        if not text.strip():
            continue
        if style is None:
            segments[index] = (text.rstrip() + suffix, style)
            return
    segments.append((suffix, None))


def _needs_gyur_suffix(paragraph: Paragraph, skip_char_style: str | None) -> bool:
    if not skip_char_style:
        return False
    for run in reversed(paragraph.runs):
        text = run.text.strip()
        if not text:
            continue
        style_name = _style_name(getattr(run, "style", None))
        if style_name != skip_char_style:
            return False
        normalized = _strip_tibetan_trailing_punctuation(text)
        return normalized in GYUR_TRIGGER_PHRASES
    return False


def _strip_tibetan_trailing_punctuation(text: str) -> str:
    stripped = text.rstrip(TIBETAN_ENDING_PUNCTUATION)
    return stripped.strip()


def _strip_tibetan_punctuation(text: str) -> str:
    return text.strip(TIBETAN_ENDING_PUNCTUATION + " ")


def _ensure_mantra_char_style(document: Document, style_name: str | None) -> None:
    if not style_name:
        return
    try:
        document.styles[style_name]
        return
    except KeyError:
        pass
    style = document.styles.add_style(style_name, WD_STYLE_TYPE.CHARACTER)
    style.font.italic = True


if __name__ == "__main__":
    main()
